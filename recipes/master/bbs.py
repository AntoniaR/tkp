#                                              LOFAR TRANSIENTS IMAGING PIPELINE
#
#                                        BBS (BlackBoard Selfcal) wrapper recipe
#                                                                Evert Rol, 2012
#                                                      software@transientskp.org
# ------------------------------------------------------------------------------

from __future__ import with_statement
import subprocess
import sys
import os
import threading
import tempfile
import shutil
import time
import signal

from lofar.parameterset import parameterset

from lofarpipe.support.baserecipe import BaseRecipe
from lofarpipe.support.group_data import load_data_map, store_data_map
from lofarpipe.support.lofarexceptions import PipelineException
from lofarpipe.support.pipelinelogging import CatchLog4CPlus
from lofarpipe.support.pipelinelogging import log_process_output
from lofarpipe.support.remotecommand import run_remote_command
from lofarpipe.support.remotecommand import ComputeJob
from lofarpipe.support.jobserver import job_server
from lofarpipe.support.parset import Parset
from lofarpipe.support.group_data import store_data_map
import lofarpipe.support.utilities as utilities
import lofarpipe.support.lofaringredient as ingredient


class bbs(BaseRecipe):
    """
    The bbs recipe acts as a wrapper around new_bbs, introducing one
    extra parameter: nproc. Based on nproc, it runs new_bbs multiple
    times, each with a different mapping file that is created from the
    original mapfile giving as input.

    **Arguments**

    A mapfile describing the data to be processed.
    """
    inputs = {
        'control_exec': ingredient.ExecField(
            '--control-exec',
            dest="control_exec",
            help="BBS Control executable"
        ),
        'kernel_exec': ingredient.ExecField(
            '--kernel-exec',
            dest="kernel_exec",
            help="BBS Kernel executable"
        ),
        'initscript': ingredient.FileField(
            '--initscript',
            dest="initscript",
            help="Initscript to source (ie, lofarinit.sh)"
        ),
        'parset': ingredient.FileField(
            '-p', '--parset',
            dest="parset",
            help="BBS configuration parset"
        ),
        'db_key': ingredient.StringField(
            '--db-key',
            dest="db_key",
            help="Key to identify BBS session"
        ),
        'db_host': ingredient.StringField(
            '--db-host',
            dest="db_host",
            help="Database host with optional port (e.g. ldb001:5432)"
        ),
        'db_user': ingredient.StringField(
            '--db-user',
            dest="db_user",
            help="Database user"
        ),
        'db_name': ingredient.StringField(
            '--db-name',
            dest="db_name",
            help="Database name"
        ),
        'instrument_mapfile': ingredient.FileField(
            '--instrument-mapfile',
            help="Full path to the mapfile containing the names of the "
                 "instrument model files generated by the `parmdb` recipe"
        ),
        'sky_mapfile': ingredient.FileField(
            '--sky-mapfile',
            help="Full path to the mapfile containing the names of the "
                 "sky model files generated by the `sourcedb` recipe"
        ),
        'nproc': ingredient.IntField(
            '--nproc',
            help="Maximum number of simultaneous processes per compute node",
            default=8
        ),
        'data_mapfile': ingredient.StringField(
            '--data-mapfile',
            help="Full path to the mapfile containing the names of the "
                 "data files that were processed by BBS (clobbered if exists)"
        )
    }
    outputs = {
        'mapfile': ingredient.FileField(
            help="Full path to a mapfile describing the processed data"
        )
    }


    def _make_partial_bbs_map(self):
        """
        Created a list of mapfile tuples from the full data mapfile,
        the instrument mapfile and the sky mapfile, but limited for
        nproc processes per host.

        It is assumed that the data, instrument and sky map files list
        their entries in corresponding order, i.e., the element i
        matches the same subband in all three mapfiles. The parmdb and
        sourcedb tasks should have taken care of this.
        """

        self.logger.debug("Creating BBS map-file using %s, %s, %s",
                          self.inputs['args'][0],
                          self.inputs['instrument_mapfile'],
                          self.inputs['sky_mapfile'])
        data_map = load_data_map(self.inputs['args'][0])
        instrument_map = load_data_map(self.inputs['instrument_mapfile'])
        sky_map = load_data_map(self.inputs['sky_mapfile'])
        nproc = self.inputs['nproc']
        mapfiles = {} #{'data': {}, 'instrument': {}, 'sky': {}}
        # This works per host, not per (sub)cluster.  We assume,
        # however, that the appropriate host/cluster to file mapping
        # has been done correctly before this task.
        # Firstly, we create a list of data, instrument and sky tuples
        # mapped to each host
        host_mapping = {}
        for i, host_data in enumerate(data_map):
            host, data = host_data
            instrument = instrument_map[i][1]
            sky = sky_map[i][1]
            host_mapping.setdefault(host, []).append((data, instrument, sky))
        # Secondly, we iterate through each host, chopping the lists up into
        # parts that are nproc long
        # We store the separate chopped lists into mapfiles
        for host, values in host_mapping.iteritems():
            data = [value[0] for value in values]
            instrument = [value[1] for value in values]
            sky = [value[2] for value in values]
            l = len(data)
            subdata = [data[i:i+nproc] for i in range(0, l, nproc)]
            subinstrument = [instrument[i:i+nproc] for i in range(0, l, nproc)]
            subsky = [sky[i:i+nproc] for i in range(0, l, nproc)]
            for isubset, sublist in enumerate(zip(subdata, subinstrument, subsky)):
                mapfiles.setdefault(isubset, {}).setdefault(host, {
                    'data': sublist[0],
                    'instrument': sublist[1],
                    'sky': sublist[2]})
        sub_mapfiles = []
        path = {}
        # Step through the subprocesses
        for mapping in mapfiles.values():
            submapping = {'data': [], 'instrument': [], 'sky': []}
            for key in ('data', 'instrument', 'sky'):
                submapping = []
                for host, maps in mapping.iteritems():
                    for value in maps[key]:
                        submapping.append((host, value))
                fh, path[key] = tempfile.mkstemp(suffix="_%s_mapfile" % key, dir=self.config.get(
                    'layout', 'parset_directory'))
                os.close(fh)
                store_data_map(path[key], submapping)
            sub_mapfiles.append((path['data'], path['instrument'], path['sky']))
        return sub_mapfiles

    def _combine_mapfiles(self, mapfiles):
        mapping = {}
        for mapfile in mapfiles:
            datamap = parameterset(mapfile)
            for host in datamap.keys():
                mapping.setdefault(host, []).extend(
                    datamap.getStringVector(host, []))
        mapfile = []
        for host, data in mapping.items():
            mapfile.append((host, data)) #addStringVector(host, data)
        return mapfile
    
    def go(self):
        self.logger.info("Starting BBS run")
        super(bbs, self).go()

        inputs = dict(self.inputs)
        del inputs['nproc']
        mapfiles = self._make_partial_bbs_map()
        self.logger.debug("temporary sub mapfiles = %s", str(mapfiles))
        new_mapfiles = []
        for mapfile in mapfiles:
            inputs['args'] = [mapfile[0]]
            inputs['instrument_mapfile'] = mapfile[1]
            inputs['sky_mapfile'] = mapfile[2]
            self.logger.info("mapfile = %s", str(mapfile))
            outputs = ingredient.LOFARoutput()
            fh, path = tempfile.mkstemp(suffix="_compute_mapfile", dir=self.config.get(
                'layout', 'parset_directory'))
            os.close(fh)
            inputs['data_mapfile'] = path
            self.cook_recipe("new_bbs", inputs, outputs)
            self.logger.debug("outputs = %s", str(outputs))
            new_mapfiles.append(outputs['mapfile'])
            # Clean up temporary input map files
            for tmpfile in mapfile:
                os.remove(tmpfile)
        mapfile = self._combine_mapfiles(new_mapfiles)
        store_data_map(self.inputs['data_mapfile'], mapfile)
        #mapfile.writeFile(self.inputs['data_mapfile'])
        # Clean up temporary output map files
        for new_mapfile in new_mapfiles:
            os.remove(new_mapfile)
        self.outputs['mapfile'] = self.inputs['data_mapfile']
        return 0


if __name__ == '__main__':
    sys.exit(new_bbs().main())
